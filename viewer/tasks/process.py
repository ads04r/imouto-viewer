import datetime, pytz, os
from background_task import background
from background_task.models import Task
from django.conf import settings

from viewer.models import WatchedDirectory, Photo, Event

from viewer.functions.photos import locate_photos_by_exif
from viewer.functions.locations import create_location_events, fill_country_cities, fill_location_cities
from viewer.functions.location_manager import get_location_manager_report_queue

from viewer.importers.upload import import_fit
from viewer.importers.location import upload_file
from viewer.importers.photos import import_photo_file
from viewer.importers.minimoods import import_mood_file

import logging
logger = logging.getLogger(__name__)

@background(schedule=0, queue='process')
def calculate_journey_distances(max=100):
	"""
	A background task that goes through all the journey Events that have no cached distance, and calculate their distance.
	Massively speeds up calculating a Month's longest journey later.

	:param max: Check a maximum of this many records before exiting.
	"""
	if Task.objects.filter(queue='process', task_name__icontains='tasks.process.calculate_journey_distances').count() > 1:
		return # If there's already an instance of this task running or queued, don't start another.
	logger.info("Task calculate_journey_distances beginning")
	i = 0
	for event in Event.objects.filter(type='journey', cached_distance=0):
		distance = event.distance()
		logger.debug("Event " + str(event.pk) + " distance is " + str(distance))
		i = i + 1
		if i >= max:
			break

@background(schedule=0, queue='process')
def generate_location_events(min_duration=300):
	"""
	Creates a set of location Events based on the no-movement periods generated by the Location Manager.

	:param min_duration: Doesn't create Events shorter than this many seconds. Good for avoiding creating 'stopped at a red light' Events.
	"""
	if Task.objects.filter(queue='process', task_name__icontains='tasks.process.generate_location_events').count() > 1:
		return # If there's already an instance of this task running or queued, don't start another.
	if len(get_location_manager_report_queue()) > 0:
		generate_location_events(min_duration=min_duration, schedule=60) # If there are tasks in the location manager, hold back until they finish
		return
	logger.info("Task generate_location_events beginning")
	create_location_events(min_duration)

@background(schedule=0, queue='process')
def fill_cities():
	"""
	Uses an OSM API to determine the cities that exist within the countries visited, and matches them
	to locations where possible.
	"""
	if Task.objects.filter(queue='process', task_name__icontains='tasks.process.fill_cities').count() > 1:
		return # If there's already an instance of this task running or queued, don't start another.
	if len(get_location_manager_report_queue()) > 0:
		fill_cities(schedule=60) # If there are tasks in the location manager, hold back until they finish
		return
	logger.info("Task fill_cities beginning")
	fill_country_cities()
	fill_location_cities()

@background(schedule=0, queue='process')
def precache_photo_thumbnails(limit=200):
	"""
	Searches for all the Photos without a cached thumbnail, and queues a `precache_photo_thumbnail` task for each one.

	:param limit: The maximum number of tasks to be created. Defaults to 200 but can be adjusted depending on system resources.
	"""
	logger.info("Task precache_photo_thumbnails beginning")
	for photo in Photo.objects.filter(cached_thumbnail=None)[0:limit]:
		precache_photo_thumbnail(photo.id)

@background(schedule=0, queue='process')
def precache_photo_thumbnail(photo_id):
	"""
	Generates and caches a single Photo's thumbnail, for quicker page rendering later.

	:param photo_id: The ID (primary key) of the Photo to process.
	"""
	photo = Photo.objects.get(id=photo_id)
	logger.debug("Precaching " + str(photo.file.path))
	try:
		im = photo.thumbnail(200)
	except:
		pass

@background(schedule=0, queue='process')
def check_watched_directories():
	"""
	Iterates through all the watched directories and begins an import for each new file found.
	"""
	if Task.objects.filter(queue='process', task_name__icontains='check_watched_directories').count() > 1:
		return # If there's already an instance of this task running or queued, don't start another.
	if len(get_location_manager_report_queue()) > 0:
		check_watched_directories(schedule=60) # If there are tasks in the location manager, hold back until they finish
		return

	ret = []
	logger.info("Task check_watched_directories beginning")
	for wd in WatchedDirectory.objects.all():
		if not(wd.needs_check):
			continue
		if not(os.path.exists(wd.path)):
			continue
		wd.last_check = pytz.utc.localize(datetime.datetime.utcnow())
		wd.save(update_fields=['last_check'])
		for fn in wd.unimported_files:
			for f in wd.known_files.all():
				if f.path == fn:
					modified_time = pytz.utc.localize(datetime.datetime.utcfromtimestamp(os.path.getmtime(fn)))
					file_size = os.path.getsize(fn)
					if((f.modified_time == modified_time) & (f.file_size == file_size)):
						ret.append(f)
					else:
						f.modified_time = modified_time
						f.file_size = file_size
						f.import_time = None
						f.save(update_fields=['import_time', 'modified_time', 'file_size'])
	last_photo = None
	for f in ret:
		if f.watched_directory.importer == 'fit':
			f.import_time = pytz.utc.localize(datetime.datetime.utcnow())
			f.save(update_fields=['import_time'])
			if upload_file(f.path, f.watched_directory.source):
				import_fit(f.path)
			else:
				f.import_time = None
				f.save(update_fields=['import_time'])
		if f.watched_directory.importer == 'gpx':
			f.import_time = pytz.utc.localize(datetime.datetime.utcnow())
			f.save(update_fields=['import_time'])
			if not(upload_file(f.path, f.watched_directory.source)):
				f.import_time = None
				f.save(update_fields=['import_time'])
		if f.watched_directory.importer == 'mood':
			f.import_time = pytz.utc.localize(datetime.datetime.utcnow())
			f.save(update_fields=['import_time'])
			ret = import_mood_file(f.path)
		if f.watched_directory.importer == 'jpg':
			f.import_time = pytz.utc.localize(datetime.datetime.utcnow())
			f.save(update_fields=['import_time'])
			photo = import_photo_file(f.path, pytz.timezone(settings.TIME_ZONE))
			if photo.time is None:
				continue
			if last_photo is None:
				last_photo = photo.time
			if photo.time < last_photo:
				last_photo = photo.time
			precache_photo_thumbnail(photo.id)
	if not(last_photo is None):
		locate_photos_by_exif(since=last_photo - datetime.timedelta(seconds=1), reassign=False)
